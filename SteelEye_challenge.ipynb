{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTJ2S7Ie258N48o7gH7m4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrodrigu12/SteelEyeAssessment/blob/main/SteelEye_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import zipfile\n",
        "import io\n",
        "import csv\n",
        "from io import StringIO\n",
        "import pandas as pd  # For creating CSV file\n",
        "import boto3\n",
        "\n",
        "# URL for downloading the XML file\n",
        "xml_url = 'https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100'\n",
        "\n",
        "# Download the XML file from the provided link\n",
        "response = requests.get(xml_url)\n",
        "\n",
        "# Parse the XML response\n",
        "root = ET.fromstring(response.content)\n",
        "\n",
        "# Find the second download link with `file_type` as \"DLTINS\"\n",
        "download_link = None\n",
        "count = 0\n",
        "\n",
        "for doc in root.findall(\".//doc\"):\n",
        "    file_type = None\n",
        "    download_link = None\n",
        "    for field in doc.findall(\".//str\"):\n",
        "        if field.attrib['name'] == 'file_type' and field.text == 'DLTINS':\n",
        "            count += 1\n",
        "            if count == 2:  # this instruction point to the second 'DLTINS' link\n",
        "                for str_element in doc.findall(\".//str\"):\n",
        "                    if str_element.attrib['name'] == 'download_link':\n",
        "                        download_link = str_element.text\n",
        "                        break\n",
        "    if download_link:\n",
        "        break\n",
        "\n",
        "if not download_link:\n",
        "    print(\"Download link for the second DLTINS file not found.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Download link found: {download_link}\")\n",
        "\n",
        "# Download the zip file from the found link\n",
        "zip_response = requests.get(download_link)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(zip_response.content))\n",
        "\n",
        "# Extract the XML from the zip file\n",
        "xml_filename = None\n",
        "for filename in zip_file.namelist():\n",
        "    if filename.endswith(\".xml\"):\n",
        "        xml_filename = filename\n",
        "        zip_file.extract(filename)\n",
        "        print(f\"Extracted file: {filename}\")\n",
        "        break\n",
        "\n",
        "if not xml_filename:\n",
        "    print(\"No XML file found in the zip archive.\")\n",
        "    exit()\n",
        "\n",
        "def xml_to_csv(xml_filename):\n",
        "    \"\"\"Parse XML and convert it to CSV.\"\"\"\n",
        "    tree = ET.parse(xml_filename)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Open a CSV file to write the data\n",
        "    with open('output.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['FinInstrmGnlAttrbts.Id', 'FinInstrmGnlAttrbts.FullNm',\n",
        "                         'FinInstrmGnlAttrbts.ClssfctnTp', 'FinInstrmGnlAttrbts.CmmdtyDerivInd',\n",
        "                         'FinInstrmGnlAttrbts.NtnlCcy', 'Issr'])\n",
        "\n",
        "        # Loop through each XML element\n",
        "        for fin_instrm in root.findall('FinInstrmGnlAttrbts'):\n",
        "            id_ = fin_instrm.find('Id').text\n",
        "            full_name = fin_instrm.find('FullNm').text\n",
        "            clssfctn_tp = fin_instrm.find('ClssfctnTp').text\n",
        "            cmmdty_deriv_ind = fin_instrm.find('CmmdtyDerivInd').text\n",
        "            ntnl_ccy = fin_instrm.find('NtnlCcy').text\n",
        "            issuer = fin_instrm.find('Issr').text\n",
        "\n",
        "            # Write each row to the CSV\n",
        "            writer.writerow([id_, full_name, clssfctn_tp, cmmdty_deriv_ind, ntnl_ccy, issuer])\n",
        "\n",
        "# Convert XML to CSV\n",
        "xml_to_csv(xml_filename)\n",
        "\n",
        "# Load the generated CSV into a DataFrame for further processing\n",
        "df = pd.read_csv('output.csv')\n",
        "\n",
        "# Add columns based on conditions descibed on requirement 5 and 6\n",
        "df['a_count'] = df['FinInstrmGnlAttrbts.FullNm'].str.count('a')\n",
        "df['contains_a'] = df['a_count'].apply(lambda x: \"YES\" if x > 0 else \"NO\")\n",
        "\n",
        "# Load new columns to DataFrame\n",
        "df.to_csv('output.csv', index=False)\n",
        "\n",
        "\n",
        "#Requirement 7 ->  this section below doesn't work due to not having created an AWS S3 bucket\n",
        "\n",
        "# Initialize S3 client\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "# Convert DataFrame to CSV format and then to an in-memory string\n",
        "csv_buffer = StringIO()\n",
        "df.to_csv(csv_buffer, index=False)\n",
        "\n",
        "# Define bucket name and file name\n",
        "bucket_test = 's3-bucket-name'\n",
        "file_output = 'AWSoutput.csv'\n",
        "\n",
        "# Upload the CSV to S3 -> The instruction below is commented on due to not having created an AWS S3 bucket\n",
        "#s3.put_object(Bucket=bucket_test, Key=file_output, Body=csv_buffer.getvalue())\n",
        "\n",
        "\n",
        "# Print final DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "74K_q-5Y0rVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2189d3d-d59f-4d80-eb33-814d6f59aa93"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download link found: https://firds.esma.europa.eu/firds/DLTINS_20210119_01of02.zip\n",
            "Extracted file: DLTINS_20210119_01of02.xml\n",
            "Empty DataFrame\n",
            "Columns: [FinInstrmGnlAttrbts.Id, FinInstrmGnlAttrbts.FullNm, FinInstrmGnlAttrbts.ClssfctnTp, FinInstrmGnlAttrbts.CmmdtyDerivInd, FinInstrmGnlAttrbts.NtnlCcy, Issr, a_count, contains_a]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # For creating CSV file\n",
        "from xml.etree import ElementTree as ET  # To parse XML\n",
        "from pathlib import Path\n",
        "import csv\n",
        "\n",
        "# Create a path object for XML and CSV files\n",
        "xml_path = Path(\"/content/test2.xml\")\n",
        "csv_path = Path(\"/testOutput.csv\")\n",
        "\n",
        "\n",
        "\n",
        "def xml_to_csv(xml_path, csv_path):\n",
        "    \"\"\"Parse XML and convert it to CSV.\"\"\"\n",
        "    # Parse the XML file\n",
        "    xml_parse = ET.parse(xml_path)\n",
        "    root = xml_parse.getroot()\n",
        "\n",
        "    # Open CSV file for writing\n",
        "    with open(csv_path, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write header (based on test2 XML structure)\n",
        "        writer.writerow(['Name', 'Position','Club'])\n",
        "\n",
        "        # Loop through each XML element\n",
        "        for player in root.findall('player'):\n",
        "            name = player.find('name').text\n",
        "            position = player.find('position').text\n",
        "            team = player.find('club').text\n",
        "\n",
        "            # Write each row to the CSV\n",
        "            writer.writerow([name, position, team])\n",
        "\n",
        "\n",
        "# Convert XML to CSV\n",
        "xml_to_csv(xml_path, csv_path)\n",
        "\n",
        "# Load CSV to DataFrame for additional processing\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Add new columns based on conditions\n",
        "df['A_count'] = df['Name'].str.count('a')\n",
        "df['contains_A'] = df['A_count'].apply(lambda x: \"YES\" if x > 0 else \"NO\")\n",
        "\n",
        "#Load new columns to DataFrame\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Print final DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "fLDVDF6FlGMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}